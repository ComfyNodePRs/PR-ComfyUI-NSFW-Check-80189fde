# NSFW Check for ComfyUI
![image](https://github.com/user-attachments/assets/a25cd166-a7ed-4d47-ac10-6100acf18cee)


## Project Overview

This project is designed to detect whether images generated by ComfyUI are Not Safe For Work (NSFW). It uses a machine learning model to classify images as either safe or not safe for work and returns a confidence score for the NSFW classification.

Using the score, a user can add logical filters to their workflow.

A threshold of 0.95 works well for most cases.

## Credits

This project is based on [ComfyUI-NSFW-Detection](https://github.com/trumanwong/ComfyUI-NSFW-Detection) by trumanwong.

## Install

1. Clone this repo into custom_nodes directory of ComfyUI location

2. Run pip install -r requirements.txt
